{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36bfafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from pyimagesearch import config\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from imutils import paths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74d4150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights = \"imagenet\",\n",
    "                  include_top = False,\n",
    "                  input_shape=(64, 64, 3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea96dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the paths to all input images in the original input directory\n",
    "# and shuffle them\n",
    "imagePaths = list(paths.list_images(config.ORIG_INPUT_DATASET))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e48cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the training and testing split\n",
    "i = int(len(imagePaths) * config.TRAIN_SPLIT)\n",
    "trainPaths = imagePaths[:i]\n",
    "testPaths = imagePaths[i:]\n",
    "\n",
    "# we'll be using part of the training data for validation\n",
    "i = int(len(trainPaths) * config.VAL_SPLIT)\n",
    "valPaths = trainPaths[:i]\n",
    "trainPaths = trainPaths[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b42d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the datasets that we'll be building\n",
    "datasets = [\n",
    "        (\"training\", trainPaths, config.TRAIN_PATH),\n",
    "        (\"validation\", valPaths, config.VAL_PATH),\n",
    "        (\"testing\", testPaths, config.TEST_PATH)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77d296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building 'training' split\n",
      "[INFO] building 'validation' split\n",
      "[INFO] building 'testing' split\n"
     ]
    }
   ],
   "source": [
    "# loop over the datasets\n",
    "\n",
    "for (dType, imagePaths, baseOutput) in datasets:\n",
    "\n",
    "    # show which data split we are creating\n",
    "    print(\"[INFO] building '{}' split\".format(dType))\n",
    "\n",
    "    # if the output base output directory does not exist, create it\n",
    "    if not os.path.exists(baseOutput):\n",
    "        print(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
    "        os.makedirs(baseOutput)\n",
    "\n",
    "    # loop over the input image paths\n",
    "    for inputPath in imagePaths:\n",
    "        # extract the filename of the input image along with its\n",
    "        # corresponding class label\n",
    "        filename = inputPath.split(os.path.sep)[-1]\n",
    "        label = inputPath.split(os.path.sep)[-2]\n",
    "\n",
    "        # build the path to the label directory\n",
    "        labelPath = os.path.sep.join([baseOutput, label])\n",
    "\n",
    "        # if the label output directory does not exist, create it\n",
    "        if not os.path.exists(labelPath):\n",
    "            print(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "            os.makedirs(labelPath)\n",
    "\n",
    "        # construct the path to the destination image and then copy\n",
    "        # the image itself\n",
    "        p = os.path.sep.join([labelPath, filename])\n",
    "        shutil.copy2(inputPath, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b46925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rescale=1 / 255.0,\n",
    "    rotation_range=40,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    #fill_mode=\"nearest\"\n",
    "    )\n",
    "\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "testAug = ImageDataGenerator(rescale=1 / 255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bea1bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the total number of epochs to train for along with the\n",
    "# initial learning rate and batch size\n",
    "NUM_EPOCHS = 50\n",
    "batch_size = 32\n",
    "\n",
    "totalTrain = len(list(paths.list_images(config.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config.TEST_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724bf3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 2, 2, 512))\n",
    "    labels = np.zeros(shape=(sample_count, 2))\n",
    "\n",
    "    generator = ImageDataGenerator(\n",
    "        rescale=1./255).flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(64, 64),\n",
    "        batch_size = batch_size, \n",
    "        color_mode=\"rgb\",\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    print('Entering for loop...');\n",
    "\n",
    "    \n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2e2e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19842 images belonging to 2 classes.\n",
      "Entering for loop...\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels, train_generator = extract_features(config.TRAIN_PATH,totalTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e29af91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2204 images belonging to 2 classes.\n",
      "Entering for loop...\n"
     ]
    }
   ],
   "source": [
    "validation_features, validation_labels, validation_generator= extract_features(config.VAL_PATH, totalVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4e8030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5512 images belonging to 2 classes.\n",
      "Entering for loop...\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels, test_generator = extract_features(config.TEST_PATH, totalTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edc7e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (totalTrain, 2 * 2 * 512))\n",
    "validation_features = np.reshape(validation_features, (totalVal, 2 * 2 * 512))\n",
    "test_features = np.reshape(test_features, (totalTest, 2 * 2 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6abe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_features', train_features)\n",
    "\n",
    "train_features = np.load('train_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65fd7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2048, activation='relu', input_dim=2 * 2 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=2 * 2 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu', input_dim=2 * 2 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff59e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,311,362\n",
      "Trainable params: 5,311,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77829b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "491e3c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "621/621 [==============================] - 20s 31ms/step - loss: 0.3956 - acc: 0.8162 - val_loss: 0.2308 - val_acc: 0.9129\n",
      "Epoch 2/50\n",
      "621/621 [==============================] - 20s 33ms/step - loss: 0.2554 - acc: 0.8968 - val_loss: 0.1991 - val_acc: 0.9256\n",
      "Epoch 3/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.2237 - acc: 0.9142 - val_loss: 0.1887 - val_acc: 0.9301\n",
      "Epoch 4/50\n",
      "621/621 [==============================] - 21s 33ms/step - loss: 0.2080 - acc: 0.9196 - val_loss: 0.1796 - val_acc: 0.9338\n",
      "Epoch 5/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1971 - acc: 0.9235 - val_loss: 0.1768 - val_acc: 0.9347\n",
      "Epoch 6/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1887 - acc: 0.9284 - val_loss: 0.1849 - val_acc: 0.9297\n",
      "Epoch 7/50\n",
      "621/621 [==============================] - 20s 33ms/step - loss: 0.1851 - acc: 0.9303 - val_loss: 0.1802 - val_acc: 0.9297\n",
      "Epoch 8/50\n",
      "621/621 [==============================] - 22s 35ms/step - loss: 0.1797 - acc: 0.9324 - val_loss: 0.1688 - val_acc: 0.9369\n",
      "Epoch 9/50\n",
      "621/621 [==============================] - 20s 33ms/step - loss: 0.1741 - acc: 0.9340 - val_loss: 0.1671 - val_acc: 0.9378\n",
      "Epoch 10/50\n",
      "621/621 [==============================] - 20s 33ms/step - loss: 0.1715 - acc: 0.9352 - val_loss: 0.1689 - val_acc: 0.9387\n",
      "Epoch 11/50\n",
      "621/621 [==============================] - 20s 33ms/step - loss: 0.1671 - acc: 0.9400 - val_loss: 0.1856 - val_acc: 0.9328\n",
      "Epoch 12/50\n",
      "621/621 [==============================] - 24s 38ms/step - loss: 0.1615 - acc: 0.9408 - val_loss: 0.1665 - val_acc: 0.9392\n",
      "Epoch 13/50\n",
      "621/621 [==============================] - 22s 35ms/step - loss: 0.1583 - acc: 0.9401 - val_loss: 0.1675 - val_acc: 0.9315\n",
      "Epoch 14/50\n",
      "621/621 [==============================] - 22s 35ms/step - loss: 0.1576 - acc: 0.9409 - val_loss: 0.1661 - val_acc: 0.9347\n",
      "Epoch 15/50\n",
      "621/621 [==============================] - 19s 30ms/step - loss: 0.1552 - acc: 0.9416 - val_loss: 0.1624 - val_acc: 0.9397\n",
      "Epoch 16/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1522 - acc: 0.9420 - val_loss: 0.1640 - val_acc: 0.9419\n",
      "Epoch 17/50\n",
      "621/621 [==============================] - 20s 33ms/step - loss: 0.1481 - acc: 0.9447 - val_loss: 0.1632 - val_acc: 0.9410\n",
      "Epoch 18/50\n",
      "621/621 [==============================] - 19s 31ms/step - loss: 0.1454 - acc: 0.9458 - val_loss: 0.1684 - val_acc: 0.9365\n",
      "Epoch 19/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1415 - acc: 0.9470 - val_loss: 0.1752 - val_acc: 0.9410\n",
      "Epoch 20/50\n",
      "621/621 [==============================] - 23s 38ms/step - loss: 0.1380 - acc: 0.9494 - val_loss: 0.1625 - val_acc: 0.9415\n",
      "Epoch 21/50\n",
      "621/621 [==============================] - 21s 34ms/step - loss: 0.1344 - acc: 0.9499 - val_loss: 0.1684 - val_acc: 0.9406\n",
      "Epoch 22/50\n",
      "621/621 [==============================] - 22s 35ms/step - loss: 0.1335 - acc: 0.9515 - val_loss: 0.1635 - val_acc: 0.9437\n",
      "Epoch 23/50\n",
      "621/621 [==============================] - 19s 31ms/step - loss: 0.1298 - acc: 0.9525 - val_loss: 0.1609 - val_acc: 0.9415\n",
      "Epoch 24/50\n",
      "621/621 [==============================] - 19s 31ms/step - loss: 0.1278 - acc: 0.9528 - val_loss: 0.1630 - val_acc: 0.9419\n",
      "Epoch 25/50\n",
      "621/621 [==============================] - 19s 31ms/step - loss: 0.1287 - acc: 0.9515 - val_loss: 0.1831 - val_acc: 0.9383\n",
      "Epoch 26/50\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 0.1238 - acc: 0.9550 - val_loss: 0.1775 - val_acc: 0.9315\n",
      "Epoch 27/50\n",
      "621/621 [==============================] - 19s 30ms/step - loss: 0.1164 - acc: 0.9572 - val_loss: 0.1761 - val_acc: 0.9369\n",
      "Epoch 28/50\n",
      "621/621 [==============================] - 19s 31ms/step - loss: 0.1186 - acc: 0.9565 - val_loss: 0.1695 - val_acc: 0.9446\n",
      "Epoch 29/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1124 - acc: 0.9589 - val_loss: 0.1746 - val_acc: 0.9415\n",
      "Epoch 30/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1141 - acc: 0.9586 - val_loss: 0.1755 - val_acc: 0.9378\n",
      "Epoch 31/50\n",
      "621/621 [==============================] - 21s 34ms/step - loss: 0.1121 - acc: 0.9594 - val_loss: 0.1963 - val_acc: 0.9383\n",
      "Epoch 32/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1068 - acc: 0.9626 - val_loss: 0.1810 - val_acc: 0.9437\n",
      "Epoch 33/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1094 - acc: 0.9608 - val_loss: 0.1758 - val_acc: 0.9428\n",
      "Epoch 34/50\n",
      "621/621 [==============================] - 20s 31ms/step - loss: 0.1046 - acc: 0.9628 - val_loss: 0.1833 - val_acc: 0.9415\n",
      "Epoch 35/50\n",
      "621/621 [==============================] - 19s 31ms/step - loss: 0.1059 - acc: 0.9607 - val_loss: 0.1768 - val_acc: 0.9415\n",
      "Epoch 36/50\n",
      "621/621 [==============================] - 22s 35ms/step - loss: 0.0991 - acc: 0.9653 - val_loss: 0.1882 - val_acc: 0.9478\n",
      "Epoch 37/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.1017 - acc: 0.9652 - val_loss: 0.1969 - val_acc: 0.9406\n",
      "Epoch 38/50\n",
      "621/621 [==============================] - 20s 31ms/step - loss: 0.1012 - acc: 0.9614 - val_loss: 0.1828 - val_acc: 0.9428\n",
      "Epoch 39/50\n",
      "621/621 [==============================] - 19s 30ms/step - loss: 0.0961 - acc: 0.9662 - val_loss: 0.1907 - val_acc: 0.9424\n",
      "Epoch 40/50\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 0.0903 - acc: 0.9682 - val_loss: 0.1813 - val_acc: 0.9442\n",
      "Epoch 41/50\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 0.0928 - acc: 0.9677 - val_loss: 0.1948 - val_acc: 0.9415\n",
      "Epoch 42/50\n",
      "621/621 [==============================] - 22s 36ms/step - loss: 0.0973 - acc: 0.9649 - val_loss: 0.2001 - val_acc: 0.9424\n",
      "Epoch 43/50\n",
      "621/621 [==============================] - 23s 36ms/step - loss: 0.0855 - acc: 0.9691 - val_loss: 0.1916 - val_acc: 0.9451\n",
      "Epoch 44/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.0837 - acc: 0.9695 - val_loss: 0.2054 - val_acc: 0.9433\n",
      "Epoch 45/50\n",
      "621/621 [==============================] - 20s 33ms/step - loss: 0.0824 - acc: 0.9715 - val_loss: 0.2329 - val_acc: 0.9383\n",
      "Epoch 46/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.0835 - acc: 0.9696 - val_loss: 0.2152 - val_acc: 0.9419\n",
      "Epoch 47/50\n",
      "621/621 [==============================] - 19s 31ms/step - loss: 0.0797 - acc: 0.9715 - val_loss: 0.2248 - val_acc: 0.9446\n",
      "Epoch 48/50\n",
      "621/621 [==============================] - 19s 30ms/step - loss: 0.0831 - acc: 0.9690 - val_loss: 0.1996 - val_acc: 0.9478\n",
      "Epoch 49/50\n",
      "621/621 [==============================] - 20s 32ms/step - loss: 0.0765 - acc: 0.9738 - val_loss: 0.2378 - val_acc: 0.9415\n",
      "Epoch 50/50\n",
      "621/621 [==============================] - 19s 31ms/step - loss: 0.0764 - acc: 0.9733 - val_loss: 0.2372 - val_acc: 0.9469\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e76d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 1s 8ms/step - loss: 0.2005 - acc: 0.9454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2005234807729721, 0.9453918933868408]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features,test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
